{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ballot_paper_classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi40znr_o3Ce",
        "colab_type": "text"
      },
      "source": [
        "# Import tensorflow libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H6_rkLutKkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense \n",
        "from tensorflow.keras import backend as K \n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qxv_AOuq02E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1EAsqz6t28L",
        "colab_type": "code",
        "outputId": "896ad82e-902b-416a-8e71-f14056c2be79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AVxkXbJjeO9",
        "colab_type": "code",
        "outputId": "23a83d41-c80b-4305-b6ac-650be07cdece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!ls '/drive/My Drive/Fusemachines Nepal/opencv'\n",
        "!cp '/drive/My Drive/Fusemachines Nepal/opencv/Train.tar.gz' ./\n",
        "\n",
        "!ls '/drive/My Drive/Fusemachines Nepal/opencv'\n",
        "!cp '/drive/My Drive/Fusemachines Nepal/opencv/Test.tar.gz' ./\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataDescription.docx  Test.tar.gz  Train.tar.gz     Untitled.ipynb\n",
            "test\t\t      train\t   Untitled0.ipynb\n",
            "DataDescription.docx  Test.tar.gz  Train.tar.gz     Untitled.ipynb\n",
            "test\t\t      train\t   Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HxaJqofkjKJ",
        "colab_type": "code",
        "outputId": "29bce669-7bed-4683-b1d7-1e790fe962d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!uname"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvsUtvE1kpuX",
        "colab_type": "code",
        "outputId": "10c7074d-9f37-4d62-ec94-0d3862e27592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!mkdir train\n",
        "!mkdir test"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘train’: File exists\n",
            "mkdir: cannot create directory ‘test’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiNmgg_rlnbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf Test.tar.gz -C test/\n",
        "!tar -xf Train.tar.gz -C train//\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqIxIS9eqDyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df = pd.read_csv('./train/testset.csv')\n",
        "df_test = pd.read_csv('./test/testset.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cENQjE3GqKLn",
        "colab_type": "text"
      },
      "source": [
        "# Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIRISV3AqHpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e74e5ce7-593e-4a6a-ea5e-3be089ace3d2"
      },
      "source": [
        "t = df['Label']\n",
        "\n",
        "t.plot.hist(grid=True, bins=48, rwidth=0.9,\n",
        "                   color='#ff6361')\n",
        "plt.title('Frequency Plot ')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', alpha=0.75)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6q-Cy6RrEX7",
        "colab_type": "text"
      },
      "source": [
        "## interpretation\n",
        "From above we can say that we have a balance dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tR34SLurWma",
        "colab_type": "text"
      },
      "source": [
        "# Image Augumentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAHPa4Narts6",
        "colab_type": "text"
      },
      "source": [
        "Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z-tI_KPuEdS",
        "colab_type": "code",
        "outputId": "bbcf625f-debd-4d9a-f947-69603b30b7ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "train_datagen=ImageDataGenerator(preprocessing_function=lambda x: (x / 127.5)-1)\n",
        "\n",
        "df_test['Label'] = df_test['Label'].astype(str)\n",
        "df['Label'] = df['Label'].astype(str)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    df, directory='./train/testset', x_col='Data', y_col='Label',\n",
        "    target_size=(224, 224)\n",
        ")\n",
        "test_generator = train_datagen.flow_from_dataframe(\n",
        "    df_test, directory='./test/testset', x_col='Data', y_col='Label',\n",
        "    target_size=(224, 224)\n",
        ")\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9600 validated image filenames belonging to 48 classes.\n",
            "Found 2609 validated image filenames belonging to 48 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZwJzS23rktp",
        "colab_type": "text"
      },
      "source": [
        "# Transfar Learning\n",
        "\n",
        "MobileNetV2 to power the next generation of mobile vision applications.\n",
        " MobileNetV2 is released as part of TensorFlow-Slim Image Classification Library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-snbNn5SvKQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model=MobileNetV2(input_shape=(224, 224, 3), include_top = False, weights = 'imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0805epWQsxDs",
        "colab_type": "text"
      },
      "source": [
        "# MobileNetV2 Convolutional Blocks\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1400/1*bqE59FvgpvoAQUMQ0WEoUA.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcPE0HLMye4N",
        "colab_type": "code",
        "outputId": "9e1d2223-26d6-4356-c1d7-081313f26b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feature_batch = base_model(train_generator[0])\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 7, 7, 1280)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgPA21nbyhdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNtzIMz_yn5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_average_layer = GlobalAveragePooling2D()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "288gD50ctPw7",
        "colab_type": "text"
      },
      "source": [
        "## Prediction_layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIDRc_NsysV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_layer = Dense(48,activation ='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4XjX3bZyu2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6-9yWWByxkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8odS1bQy0rH",
        "colab_type": "code",
        "outputId": "fcfb767d-bc72-427f-9051-8e559f434df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 48)                61488     \n",
            "=================================================================\n",
            "Total params: 2,319,472\n",
            "Trainable params: 61,488\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uypfR8cy62P",
        "colab_type": "code",
        "outputId": "6cb4a197-bcc5-45fb-b0e0-e7af792e5f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "model.fit(train_generator,epochs=20)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "300/300 [==============================] - 42s 138ms/step - loss: 3.8746 - accuracy: 0.0452\n",
            "Epoch 2/20\n",
            "300/300 [==============================] - 42s 139ms/step - loss: 3.5857 - accuracy: 0.0977\n",
            "Epoch 3/20\n",
            "300/300 [==============================] - 41s 138ms/step - loss: 3.3743 - accuracy: 0.1550\n",
            "Epoch 4/20\n",
            "300/300 [==============================] - 42s 139ms/step - loss: 3.1733 - accuracy: 0.2120\n",
            "Epoch 5/20\n",
            "300/300 [==============================] - 42s 138ms/step - loss: 2.9977 - accuracy: 0.2675\n",
            "Epoch 6/20\n",
            "300/300 [==============================] - 42s 138ms/step - loss: 2.8425 - accuracy: 0.3156\n",
            "Epoch 7/20\n",
            "300/300 [==============================] - 42s 139ms/step - loss: 2.7090 - accuracy: 0.3504\n",
            "Epoch 8/20\n",
            "300/300 [==============================] - 43s 142ms/step - loss: 2.5852 - accuracy: 0.3696\n",
            "Epoch 9/20\n",
            "300/300 [==============================] - 42s 140ms/step - loss: 2.4712 - accuracy: 0.4149\n",
            "Epoch 10/20\n",
            "300/300 [==============================] - 42s 141ms/step - loss: 2.3660 - accuracy: 0.4525\n",
            "Epoch 11/20\n",
            "300/300 [==============================] - 42s 141ms/step - loss: 2.2778 - accuracy: 0.4689\n",
            "Epoch 12/20\n",
            "300/300 [==============================] - 42s 140ms/step - loss: 2.1825 - accuracy: 0.5024\n",
            "Epoch 13/20\n",
            "300/300 [==============================] - 43s 142ms/step - loss: 2.1057 - accuracy: 0.5274\n",
            "Epoch 14/20\n",
            "300/300 [==============================] - 43s 143ms/step - loss: 2.0295 - accuracy: 0.5460\n",
            "Epoch 15/20\n",
            "300/300 [==============================] - 42s 140ms/step - loss: 1.9656 - accuracy: 0.5670\n",
            "Epoch 16/20\n",
            "300/300 [==============================] - 42s 141ms/step - loss: 1.8924 - accuracy: 0.5852\n",
            "Epoch 17/20\n",
            "300/300 [==============================] - 42s 140ms/step - loss: 1.8334 - accuracy: 0.6032\n",
            "Epoch 18/20\n",
            "300/300 [==============================] - 42s 139ms/step - loss: 1.7795 - accuracy: 0.6182\n",
            "Epoch 19/20\n",
            "300/300 [==============================] - 42s 140ms/step - loss: 1.7243 - accuracy: 0.6253\n",
            "Epoch 20/20\n",
            "300/300 [==============================] - 42s 139ms/step - loss: 1.6735 - accuracy: 0.6423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcf98158898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoCqmk54XrCB",
        "colab_type": "code",
        "outputId": "5cad7fe0-ad45-46b7-e1eb-dbd84d9adf86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(test_generator)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82/82 [==============================] - 11s 137ms/step - loss: 1.6545 - accuracy: 0.6328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6545090675354004, 0.6328095197677612]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M01-0kbMJBnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=model.predict(test_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOemdV2vyV5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "predicted_class_indices=np.argmax(pred,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDxWBevxJJJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbjcEAijJNHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames=test_generator.filenames\n",
        "results=pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})\n",
        "results.to_csv(\"results1.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6IobjT2ye0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c7d31861-a619-46a4-8c5f-fd4ad59eaed1"
      },
      "source": [
        "pd.read_csv('./results1.csv')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>632755.jpeg</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>496855.jpeg</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155390.jpeg</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>265013.jpeg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>496360.jpeg</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2604</th>\n",
              "      <td>542827.jpeg</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2605</th>\n",
              "      <td>962019.jpeg</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2606</th>\n",
              "      <td>518649.jpeg</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2607</th>\n",
              "      <td>299155.jpeg</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2608</th>\n",
              "      <td>360063.jpeg</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2609 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Filename  Predictions\n",
              "0     632755.jpeg           16\n",
              "1     496855.jpeg           19\n",
              "2     155390.jpeg           32\n",
              "3     265013.jpeg            3\n",
              "4     496360.jpeg           16\n",
              "...           ...          ...\n",
              "2604  542827.jpeg           23\n",
              "2605  962019.jpeg           31\n",
              "2606  518649.jpeg           47\n",
              "2607  299155.jpeg           16\n",
              "2608  360063.jpeg           23\n",
              "\n",
              "[2609 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}